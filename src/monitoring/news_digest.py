"""Personalized news digest generator.

Collects data from TMDB, web search, and user profile to generate
Claude-powered personalized cinema news digests.

Two formats:
- Daily: short evening briefing (3-5 topics)
- Weekly: comprehensive digest like a podcast episode (7-10 topics)
"""

import hashlib
import json
from datetime import date
from typing import TYPE_CHECKING, Any

import structlog

from src.config import settings
from src.user.storage import Download, get_storage

if TYPE_CHECKING:
    from telegram import Bot

logger = structlog.get_logger(__name__)

# Digest delivery settings
DAILY_DIGEST_HOUR = 19  # 19:00 in user's timezone
WEEKLY_DIGEST_DAYS = (1, 4)  # Tuesday and Friday (0=Monday)
WEEKLY_DIGEST_HOUR = 19


async def collect_digest_data(user_id: int) -> dict[str, Any]:
    """Collect raw data for digest generation.

    Fetches trending movies, premieres, digital releases, anniversaries,
    and user-specific context.

    Args:
        user_id: Internal user ID

    Returns:
        Dict with all raw data for Claude to compose the digest
    """
    from src.media.tmdb import TMDBClient
    from src.user.memory import CoreMemoryManager

    data: dict[str, Any] = {}
    today = date.today()

    async with get_storage() as storage:
        # User profile context
        memory_manager = CoreMemoryManager(storage)
        blocks = await memory_manager.get_all_blocks(user_id)
        profile_context = ""
        for block in blocks:
            if block.content:
                profile_context += f"\n{block.block_name}: {block.content}"
        data["user_profile"] = profile_context

        # Recent watch history
        watched = await storage.get_watched(user_id, limit=20)
        data["recent_watched"] = [
            {"title": w.title, "rating": w.rating, "media_type": w.media_type} for w in watched
        ]

        # Recent unreviewed downloads (for natural follow-up)
        downloads = await storage.get_recent_unreviewed_downloads(user_id, days=14)
        data["unreviewed_downloads"] = [
            {
                "id": d.id,
                "title": d.title,
                "media_type": d.media_type,
                "downloaded_at": d.downloaded_at.isoformat(),
                "season": d.season,
                "episode": d.episode,
            }
            for d in downloads
        ]

        # Watchlist
        watchlist = await storage.get_watchlist(user_id, limit=10)
        data["watchlist"] = [{"title": w.title, "media_type": w.media_type} for w in watchlist]

        # Blocklist (to avoid mentioning)
        blocklist = await storage.get_blocklist(user_id)
        data["blocklist"] = [
            {"type": b.block_type, "value": b.block_value, "level": b.block_level}
            for b in blocklist
        ]

        # User preferences
        prefs = await storage.get_preferences(user_id)
        if prefs:
            data["preferences"] = {
                "quality": prefs.video_quality,
                "audio_language": prefs.audio_language,
                "genres": prefs.preferred_genres,
            }

    # TMDB data
    try:
        async with TMDBClient() as tmdb:
            data["trending"] = await tmdb.get_trending("all", "day")
            data["now_playing"] = await tmdb.get_now_playing()
            data["upcoming"] = await tmdb.get_upcoming_movies()
            data["recently_digital"] = await tmdb.get_recently_released_digital()

            # Anniversary movies for today
            month_day = today.strftime("%m-%d")
            data["anniversaries"] = await tmdb.discover_anniversary_movies(month_day)
    except Exception as e:
        logger.warning("digest_tmdb_data_failed", error=str(e))
        data.setdefault("trending", [])
        data.setdefault("now_playing", [])
        data.setdefault("upcoming", [])
        data.setdefault("recently_digital", [])
        data.setdefault("anniversaries", [])

    # Web search for industry news
    try:
        from src.services.news import NewsService

        async with NewsService() as news_service:
            news_items = await news_service.get_relevant_news(
                keywords=["Oscar", "Golden Globe", "Cannes", "–∫–∏–Ω–æ", "—Å–µ—Ä–∏–∞–ª—ã", "Netflix", "A24"],
                hours=48,
                max_results=10,
            )
            data["industry_news"] = [
                {
                    "title": n.title,
                    "description": n.description[:200],
                    "source": n.source,
                }
                for n in news_items
            ]
    except Exception as e:
        logger.debug("digest_news_fetch_failed", error=str(e))
        data["industry_news"] = []

    return data


async def generate_digest(
    user_id: int,
    telegram_id: int,
    digest_type: str = "daily",
) -> tuple[str, list[Download]] | None:
    """Generate a personalized digest using Claude.

    Args:
        user_id: Internal user ID
        telegram_id: Telegram user ID (for entity links)
        digest_type: "daily" or "weekly"

    Returns:
        Tuple of (digest HTML text, downloads mentioned for follow-up marking)
        or None if generation fails
    """
    import anthropic

    data = await collect_digest_data(user_id)

    if digest_type == "daily":
        prompt = _build_daily_prompt(data, telegram_id)
    else:
        prompt = _build_weekly_prompt(data, telegram_id)

    try:
        client = anthropic.AsyncAnthropic(api_key=settings.anthropic_api_key.get_secret_value())

        if digest_type == "weekly":
            # Weekly digest uses Opus with extended thinking for deeper analysis
            message = await client.messages.create(
                model="claude-opus-4-5-20250514",
                max_tokens=16000,
                thinking={
                    "type": "enabled",
                    "budget_tokens": 10000,
                },
                messages=[{"role": "user", "content": prompt}],
            )
        else:
            # Daily digest uses Sonnet for speed
            message = await client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=2000,
                messages=[{"role": "user", "content": prompt}],
            )

        response = ""
        for block in message.content:
            if hasattr(block, "text"):
                response += block.text

        if not response.strip():
            logger.warning("digest_empty_response", user_id=user_id)
            return None

        # Convert markdown links to HTML for Telegram
        from src.bot.streaming import _markdown_to_telegram_html

        html_text = _markdown_to_telegram_html(response)

        # Track which downloads were mentioned
        mentioned_downloads = []
        for d in data.get("unreviewed_downloads", []):
            if d["title"].lower() in response.lower():
                # Find the actual Download object
                async with get_storage() as storage:
                    downloads = await storage.get_recent_unreviewed_downloads(user_id)
                    for dl in downloads:
                        if dl.id == d["id"]:
                            mentioned_downloads.append(dl)
                            break

        return html_text, mentioned_downloads

    except Exception as e:
        logger.exception("digest_generation_failed", user_id=user_id, error=str(e))
        return None


def _build_daily_prompt(data: dict[str, Any], telegram_id: int) -> str:
    """Build the prompt for daily digest generation."""
    bot_username = settings.bot_username
    today = date.today()

    return f"""–¢—ã ‚Äî –≤–µ–¥—É—â–∏–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–≥–æ –≤–µ—á–µ—Ä–Ω–µ–≥–æ –∫–∏–Ω–æ–±—Ä–∏—Ñ–∏–Ω–≥–∞. –¢–≤–æ–π —Å—Ç–∏–ª—å ‚Äî –∫–∞–∫ —É –ª—É—á—à–∏—Ö –∫–∏–Ω–æ-–ø–æ–¥–∫–∞—Å—Ç–æ–≤:
–Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π, –æ—Å—Ç—Ä–æ—É–º–Ω—ã–π, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π. –ë–µ–∑ –∫–∞–Ω—Ü–µ–ª—è—Ä–∏–∑–º–æ–≤ –∏ –±–µ–∑ –≤–æ—Å—Ç–æ—Ä–∂–µ–Ω–Ω–æ—Å—Ç–∏. –ö–∞–∫ —Ä–∞–∑–≥–æ–≤–æ—Ä —Å
–Ω–∞—á–∏—Ç–∞–Ω–Ω—ã–º –¥—Ä—É–≥–æ–º, –∫–æ—Ç–æ—Ä—ã–π –¥–µ—Ä–∂–∏—Ç —Ä—É–∫—É –Ω–∞ –ø—É–ª—å—Å–µ –∏–Ω–¥—É—Å—Ç—Ä–∏–∏.

–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç (3-5 —Ç–µ–º) –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

## –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
{data.get("user_profile", "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")}

## –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
{json.dumps(data.get("preferences", {}), ensure_ascii=False)}

## –ù–µ–¥–∞–≤–Ω–æ —Å–º–æ—Ç—Ä–µ–ª
{json.dumps(data.get("recent_watched", []), ensure_ascii=False)}

## –í watchlist
{json.dumps(data.get("watchlist", []), ensure_ascii=False)}

## Blocklist (–ù–ï —É–ø–æ–º–∏–Ω–∞–π!)
{json.dumps(data.get("blocklist", []), ensure_ascii=False)}

## –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞

### –¢—Ä–µ–Ω–¥—ã –¥–Ω—è
{json.dumps(data.get("trending", [])[:10], ensure_ascii=False)}

### –°–µ–π—á–∞—Å –≤ –∫–∏–Ω–æ
{json.dumps(data.get("now_playing", [])[:8], ensure_ascii=False)}

### –ü–æ—è–≤–∏–ª–æ—Å—å –≤ —Ü–∏—Ñ—Ä–µ (–º–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å)
{json.dumps(data.get("recently_digital", [])[:8], ensure_ascii=False)}

### –ü–∞–º—è—Ç–Ω—ã–µ –¥–∞—Ç—ã ‚Äî —Ñ–∏–ª—å–º—ã –≤—ã—à–µ–¥—à–∏–µ –≤ —ç—Ç–æ—Ç –¥–µ–Ω—å
{json.dumps(data.get("anniversaries", []), ensure_ascii=False)}

### –ò–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
{json.dumps(data.get("industry_news", []), ensure_ascii=False)}

### –ù–µ–¥–∞–≤–Ω–∏–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–Ω–µ –æ—Ç—Ä–µ—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
{json.dumps(data.get("unreviewed_downloads", []), ensure_ascii=False)}

## –§–æ—Ä–º–∞—Ç

–°–µ–≥–æ–¥–Ω—è—à–Ω—è—è –¥–∞—Ç–∞: {today.isoformat()}

–ù–∞–ø–∏—à–∏ –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ —ç—Ç–∏–º –ø—Ä–∞–≤–∏–ª–∞–º:
1. **3-5 —Ç–µ–º**, —Å–∞–º—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö –¥–ª—è –≠–¢–û–ì–û –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—É—á–∏—Ç—ã–≤–∞–π –µ–≥–æ –≤–∫—É—Å—ã!)
2. –ù–∞—á–Ω–∏ —Å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è (–æ–¥–Ω–∞ —Å—Ç—Ä–æ—á–∫–∞, –Ω–µ –ø–∞—Ñ–æ—Å–Ω–∞—è)
3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∏–ª—å–º–∞/—Å–µ—Ä–∏–∞–ª–∞ –¥–µ–ª–∞–π entity-—Å—Å—ã–ª–∫—É: [–ù–∞–∑–≤–∞–Ω–∏–µ](https://t.me/{bot_username}?start=m_TMDB_ID) –¥–ª—è —Ñ–∏–ª—å–º–æ–≤, t_ –¥–ª—è —Å–µ—Ä–∏–∞–ª–æ–≤, p_ –¥–ª—è –ª—é–¥–µ–π
4. –ï—Å–ª–∏ –µ—Å—Ç—å –ø–∞–º—è—Ç–Ω–∞—è –¥–∞—Ç–∞ ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–∫–ª—é—á–∏, —ç—Ç–æ –∏–∑—é–º–∏–Ω–∫–∞
5. –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç—å –∏–∑ —Ü–∏—Ñ—Ä—ã ‚Äî –æ—Ç–º–µ—Ç—å —á—Ç–æ ¬´–º–æ–∂–Ω–æ —É–∂–µ —Å–∫–∞—á–∞—Ç—å¬ª
6. –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Ä–µ—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è ‚Äî –ú–ò–ú–û–•–û–î–û–ú —Å–ø—Ä–æ—Å–∏ –ø—Ä–æ –æ–¥–Ω–æ: ¬´–ö—Å—Ç–∞—Ç–∏, –∫–∞–∫ –≤–∞–º X?¬ª (–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ)
7. –ê–¥–∞–ø—Ç–∏—Ä—É–π —Å–ª–æ–∂–Ω–æ—Å—Ç—å: –µ—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∏–Ω–µ—Ñ–∏–ª–∞ ‚Äî –º–æ–∂–Ω–æ –≥–ª—É–±–∂–µ, –µ—Å–ª–∏ casual ‚Äî –ø—Ä–æ—â–µ
8. –ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –Ω–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –≤ —Å–∫–æ–±–∫–∞—Ö
9. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è —ç–º–æ—Ü–∏–π. –¢–æ–ª—å–∫–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ: üì∞ üé¨ üì∫ üíø üìÖ
10. –í –∫–æ–Ω—Ü–µ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–π (–Ω–∏–∫–∞–∫–∏—Ö ¬´—Ö–æ—Ä–æ—à–µ–≥–æ –≤–µ—á–µ—Ä–∞¬ª)
11. –§–æ—Ä–º–∞—Ç ‚Äî Telegram HTML. –ò—Å–ø–æ–ª—å–∑—É–π <b>, <i>, <a href="...">. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π Markdown.
12. –ú–∞–∫—Å–∏–º—É–º 1500 —Å–∏–º–≤–æ–ª–æ–≤."""


def _build_weekly_prompt(data: dict[str, Any], telegram_id: int) -> str:
    """Build the prompt for weekly digest generation."""
    bot_username = settings.bot_username
    today = date.today()

    return f"""–¢—ã ‚Äî –≤–µ–¥—É—â–∏–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–≥–æ –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ –∫–∏–Ω–æ–¥–∞–π–¥–∂–µ—Å—Ç–∞. –§–æ—Ä–º–∞—Ç ‚Äî –∫–∞–∫ –≤—ã–ø—É—Å–∫ –ø–æ–¥–∫–∞—Å—Ç–∞ The Town
–∏–ª–∏ The Big Picture: –æ–±—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π, —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –º–Ω–µ–Ω–∏–µ–º, –Ω–æ –±–µ–∑ –∑–∞–Ω—É–¥—Å—Ç–≤–∞. –≠—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–æ–∫
–Ω–æ–≤–æ—Å—Ç–µ–π, –∞ –∫—É—Ä–∞—Ç–æ—Ä—Å–∫–∏–π –æ–±–∑–æ—Ä –Ω–µ–¥–µ–ª–∏, —Å–¥–µ–ª–∞–Ω–Ω—ã–π —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞.

–ù–∞–ø–∏—à–∏ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç (7-10 —Ç–µ–º).

## –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
{data.get("user_profile", "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")}

## –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
{json.dumps(data.get("preferences", {}), ensure_ascii=False)}

## –ù–µ–¥–∞–≤–Ω–æ —Å–º–æ—Ç—Ä–µ–ª
{json.dumps(data.get("recent_watched", []), ensure_ascii=False)}

## –í watchlist
{json.dumps(data.get("watchlist", []), ensure_ascii=False)}

## Blocklist (–ù–ï —É–ø–æ–º–∏–Ω–∞–π!)
{json.dumps(data.get("blocklist", []), ensure_ascii=False)}

## –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ

### –¢—Ä–µ–Ω–¥—ã –Ω–µ–¥–µ–ª–∏
{json.dumps(data.get("trending", []), ensure_ascii=False)}

### –°–µ–π—á–∞—Å –≤ –∫–∏–Ω–æ
{json.dumps(data.get("now_playing", []), ensure_ascii=False)}

### –°–∫–æ—Ä–æ –≤—ã—Ö–æ–¥–∏—Ç
{json.dumps(data.get("upcoming", []), ensure_ascii=False)}

### –ü–æ—è–≤–∏–ª–æ—Å—å –≤ —Ü–∏—Ñ—Ä–µ
{json.dumps(data.get("recently_digital", []), ensure_ascii=False)}

### –ü–∞–º—è—Ç–Ω—ã–µ –¥–∞—Ç—ã
{json.dumps(data.get("anniversaries", []), ensure_ascii=False)}

### –ò–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
{json.dumps(data.get("industry_news", []), ensure_ascii=False)}

### –ù–µ–¥–∞–≤–Ω–∏–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–Ω–µ –æ—Ç—Ä–µ—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
{json.dumps(data.get("unreviewed_downloads", []), ensure_ascii=False)}

## –§–æ—Ä–º–∞—Ç

–°–µ–≥–æ–¥–Ω—è—à–Ω—è—è –¥–∞—Ç–∞: {today.isoformat()}

–ü—Ä–∞–≤–∏–ª–∞:
1. **7-10 —Ç–µ–º**, –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–¥ –≤–∫—É—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
   - –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ (1 —Å—Ç—Ä–æ—á–∫–∞)
   - üì∞ **–ì–ª–∞–≤–Ω–æ–µ –∑–∞ –Ω–µ–¥–µ–ª—é** (2-3 –∫—Ä—É–ø–Ω—ã—Ö –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–∏)
   - üé¨ **–ü—Ä–µ–º—å–µ—Ä—ã** (—á—Ç–æ –≤—ã—à–ª–æ –≤ –∫–∏–Ω–æ –∏ –Ω–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞—Ö)
   - üíø **–ü–æ—è–≤–∏–ª–æ—Å—å –≤ —Ü–∏—Ñ—Ä–µ** (—á—Ç–æ —Ç–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å)
   - üìÖ **–î–∞—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏–∏** (–ø–∞–º—è—Ç–Ω–∞—è –¥–∞—Ç–∞ + —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å)
   - üéØ **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –Ω–µ–¥–µ–ª–∏** (–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è, –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ñ–∏–ª—è)
3. Entity-—Å—Å—ã–ª–∫–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã: <a href="https://t.me/{bot_username}?start=m_TMDB_ID">–ù–∞–∑–≤–∞–Ω–∏–µ</a>
4. –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Ä–µ—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è ‚Äî –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ —Å–ø—Ä–æ—Å–∏ ¬´–ö—Å—Ç–∞—Ç–∏, –∫–∞–∫ –≤–∞–º X?¬ª
5. –î–∞–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: –ø–æ—á–µ–º—É —ç—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –ò–ú–ï–ù–ù–û —ç—Ç–æ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
6. –ú–æ–∂–Ω–æ –ø–æ–∑–≤–æ–ª–∏—Ç—å —Å–µ–±–µ –º–Ω–µ–Ω–∏–µ (–Ω–æ –Ω–µ –Ω–∞–≤—è–∑—ã–≤–∞—Ç—å)
7. –†—É—Å—Å–∫–∏–π —è–∑—ã–∫, –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –≤ —Å–∫–æ–±–∫–∞—Ö
8. –ë–µ–∑ —ç–º–æ–¥–∑–∏ –¥–ª—è —ç–º–æ—Ü–∏–π
9. –§–æ—Ä–º–∞—Ç ‚Äî Telegram HTML. <b>, <i>, <a href="...">.
10. –ú–∞–∫—Å–∏–º—É–º 3000 —Å–∏–º–≤–æ–ª–æ–≤."""


def compute_content_hash(data: dict[str, Any]) -> str:
    """Compute a hash of digest content to avoid duplicates."""
    # Use trending + anniversaries + news as key differentiators
    key_items = []
    for item in data.get("trending", [])[:5]:
        key_items.append(str(item.get("id", "")))
    for item in data.get("anniversaries", [])[:3]:
        key_items.append(str(item.get("id", "")))
    for item in data.get("industry_news", [])[:3]:
        key_items.append(item.get("title", "")[:50])

    content = "|".join(key_items)
    return hashlib.md5(content.encode()).hexdigest()[:16]


async def send_digest(
    bot: "Bot",
    user_id: int,
    telegram_id: int,
    digest_type: str = "daily",
) -> bool:
    """Generate and send a personalized digest to a user.

    Args:
        bot: Telegram Bot instance
        user_id: Internal user ID
        telegram_id: Telegram chat ID
        digest_type: "daily" or "weekly"

    Returns:
        True if digest was sent successfully
    """
    from telegram import InlineKeyboardButton, InlineKeyboardMarkup

    result = await generate_digest(user_id, telegram_id, digest_type)
    if not result:
        logger.warning("digest_generation_returned_none", user_id=user_id)
        return False

    html_text, mentioned_downloads = result

    # Add frequency selection buttons if this is the first digest
    async with get_storage() as storage:
        last_time = await storage.get_last_digest_time(user_id, "daily")
        is_first = last_time is None

        # Also check weekly
        if is_first:
            last_weekly = await storage.get_last_digest_time(user_id, "weekly")
            is_first = last_weekly is None

    keyboard = None
    if is_first:
        buttons = [
            [
                InlineKeyboardButton("üì¨ –ï–∂–µ–¥–Ω–µ–≤–Ω–æ", callback_data="digest_freq_daily"),
                InlineKeyboardButton("üìã 2 —Ä/–Ω–µ–¥", callback_data="digest_freq_weekly"),
                InlineKeyboardButton("üîï –û—Ç–∫–ª—é—á–∏—Ç—å", callback_data="digest_freq_none"),
            ]
        ]
        keyboard = InlineKeyboardMarkup(buttons)

    try:
        await bot.send_message(
            chat_id=telegram_id,
            text=html_text,
            parse_mode="HTML",
            reply_markup=keyboard,
            disable_web_page_preview=True,
        )
    except Exception:
        # Fallback: strip HTML and send plain
        import re

        plain = re.sub(r"<[^>]+>", "", html_text)
        try:
            await bot.send_message(
                chat_id=telegram_id,
                text=plain,
                reply_markup=keyboard,
            )
        except Exception as e:
            logger.error("digest_send_failed", user_id=user_id, error=str(e))
            return False

    # Record digest history
    async with get_storage() as storage:
        data = await collect_digest_data(user_id)
        content_hash = compute_content_hash(data)
        await storage.add_digest_history(user_id, digest_type, content_hash)

        # Mark mentioned downloads as followed up
        for dl in mentioned_downloads:
            await storage.mark_followup_sent(dl.id)

    logger.info(
        "digest_sent",
        user_id=user_id,
        telegram_id=telegram_id,
        digest_type=digest_type,
        downloads_mentioned=len(mentioned_downloads),
    )
    return True
